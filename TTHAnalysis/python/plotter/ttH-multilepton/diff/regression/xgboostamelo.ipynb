{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.22/02\n",
      "You are running on  wudangshan\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from train_utils import *\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "\n",
    "import uproot\n",
    "from root_pandas import read_root\n",
    "\n",
    "\n",
    "import socket\n",
    "my_hostname=socket.gethostbyaddr(socket.gethostname())[0]\n",
    "print('You are running on ', my_hostname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "def load_data(debug=False):\n",
    "    idir = '{}'.format('/nfs/user/pvischia/tth/dnn/' if 'cism.ucl.be' in my_hostname else './')\n",
    "    file_tth = \"{}/tree_2lss1tau.root\".format(idir)\n",
    "    key = \"Friends\"\n",
    "    data_tth_orig = read_root(file_tth, key)\n",
    "    if debug:\n",
    "        data_tth_orig.describe()\n",
    "    return data_tth_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# De-jag the data with respect to the jets\n",
    "\n",
    "def dejag_data(data, debug=False):\n",
    "    test=data['SelJet_pt']\n",
    "    l = [len(i) for i in test]\n",
    "    maxl = max(l)\n",
    "\n",
    "    for lab in ['pt', 'eta', 'phi', 'mass', 'isBtag', 'isFromHadTop', 'btagDeepFlavB']:\n",
    "        label='SelJet_%s'%lab\n",
    "        tempLab=data[label]\n",
    "        data.drop([label], axis=1, inplace=True)\n",
    "        out = pd.DataFrame(tempLab.tolist(),columns=[ 'SelJet%s_%s'%(i, lab) for i in range(maxl)])\n",
    "        data = pd.concat([data, out], axis=1)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove ill-defined mass columns\n",
    "def remove_masses(data, debug=False):\n",
    "    for lab in data.columns:\n",
    "        if 'mass' in lab:\n",
    "            data.drop([lab], axis=1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_feature_names(useJets=0, debug=False):\n",
    "    thevars=[\n",
    "            'Lep1_pt', \n",
    "            'Lep2_pt', 'Lep1_eta', 'Lep2_eta', 'Lep1_phi', 'Lep2_phi',\n",
    "             'nSelJets',\n",
    "             'met', 'met_phi', \n",
    "             'HTT_score', \n",
    "             'Hj_tagger_hadTop',\n",
    "             'mindr_lep2_jet', 'mindr_lep1_jet', 'avg_dr_jet',\n",
    "             'dPhiLL_BBframe_2lss', 'dEtaLL_BBframe_2lss', 'dPhiBB_LLframe_2lss',\n",
    "             'dEtaBB_LLframe_2lss',\n",
    "             'dEtaBB_2lss',\n",
    "             'mTTH_2lss1tau',\n",
    "             'theta_higgs_ttbar_TTHsystem_2lss1tau',\n",
    "             'thetaTopTop_ttbarframe_2lss1tau', \n",
    "             'Tau_pt', 'Tau_eta', 'Tau_phi'\n",
    "            ]\n",
    "    if useJets>0:\n",
    "        for i in range(useJets):\n",
    "            thevars.append('SelJet%s_pt'%i)\n",
    "            thevars.append('SelJet%s_eta'%i)\n",
    "            thevars.append('SelJet%s_phi'%i)\n",
    "            #thevars.append('SelJet%s_mass'%i)\n",
    "            thevars.append('SelJet%s_isBtag'%i)\n",
    "            thevars.append('SelJet%s_isFromHadTop'%i)\n",
    "            thevars.append('SelJet%s_btagDeepFlavB'%i)\n",
    "    if debug:\n",
    "        print('Training features:', thevars)\n",
    "        \n",
    "    return thevars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_and_test(data, features, oddevensplit=False, fillna=False, debug=False):\n",
    "    labs=deepcopy(features)\n",
    "    if oddevensplit:\n",
    "        labs.append('event')\n",
    "    bkg = data[labs]\n",
    "    sig = data[labs]\n",
    "\n",
    "    if fillna:\n",
    "        bkg.fillna(0, inplace=True)\n",
    "        sig.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "    wgtbkg=pd.DataFrame(data['weight_SM'].tolist(), columns=['weight'])\n",
    "    wgtsig=pd.DataFrame(data['weight_CP_odd'].tolist(), columns=['weight'])\n",
    "\n",
    "    labbkg = pd.DataFrame(np.zeros_like(bkg['Lep1_pt']).tolist(), columns=['label'])\n",
    "    labsig = pd.DataFrame(np.ones_like(bkg['Lep1_pt']).tolist(), columns=['label'])\n",
    "\n",
    "    bkg = pd.concat([bkg, wgtbkg, labbkg], axis=1)\n",
    "    sig = pd.concat([sig, wgtsig, labsig], axis=1)\n",
    "\n",
    "    sig['weight'] = sig['weight'].apply(lambda x: x if x <10. else 10.)\n",
    "\n",
    "    labelled_set=pd.concat([sig, bkg], axis=0)\n",
    "    if False:\n",
    "        sns.pairplot(labelled_set, hue='label')\n",
    "    if oddevensplit:\n",
    "        labs.append('weight')\n",
    "        X=labelled_set[labs]\n",
    "        y=labelled_set['label']\n",
    "        weight=labelled_set['weight']\n",
    "        if debug:\n",
    "            pd.set_option('display.max_columns', None)\n",
    "            print(bkg.head())\n",
    "            print(sig.head())\n",
    "\n",
    "        X_wgt=X['weight']\n",
    "\n",
    "        X_train=X[X['event']%2 == 0]\n",
    "        X_test =X[X['event']%2 != 0]\n",
    "        y_train=y[X['event']%2 == 0]\n",
    "        y_test =y[X['event']%2 != 0]\n",
    "        \n",
    "        X_train_wgt=X_train['weight']\n",
    "        X_train=X_train.drop(['weight'], axis=1, inplace=False)\n",
    "        X_train=X_train.drop(['event'], axis=1, inplace=False)\n",
    "\n",
    "        X_test_wgt=X_test['weight']\n",
    "        X_test=X_test.drop(['weight'], axis=1, inplace=False)\n",
    "        X_test=X_test.drop(['event'], axis=1, inplace=False)\n",
    "\n",
    "        return {'X_train'     : X_train,\n",
    "                'X_test'      : X_test, \n",
    "                'X_train_wgt' : X_train_wgt,\n",
    "                'X_test_wgt'  : X_test_wgt,\n",
    "                'y_train'     : y_train,\n",
    "                'y_test'      : y_test \n",
    "               }\n",
    "    else:\n",
    "        labelled_set=shuffle(labelled_set)\n",
    "        labs.append('weight')\n",
    "        X=labelled_set[labs]\n",
    "        y=labelled_set['label']\n",
    "        weight=labelled_set['weight']\n",
    "        if debug:\n",
    "            pd.set_option('display.max_columns', None)\n",
    "            print(bkg.head())\n",
    "            print(sig.head())\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1534534, shuffle=True)\n",
    "\n",
    "        X_train_wgt=X_train['weight']\n",
    "        X_train=X_train.drop(['weight'], axis=1, inplace=False)\n",
    "        X_test_wgt=X_test['weight']\n",
    "        X_test=X_test.drop(['weight'], axis=1, inplace=False)\n",
    "\n",
    "        return {'X_train'     : X_train,\n",
    "                'X_test'      : X_test, \n",
    "                'X_train_wgt' : X_train_wgt,\n",
    "                'X_test_wgt'  : X_test_wgt,\n",
    "                'y_train'     : y_train,\n",
    "                'y_test'      : y_test\n",
    "               }\n",
    "        #train_dmatrix = xgb.DMatrix(data=X_train,label=y_train,weight=X_train_wgt)\n",
    "        #test_dmatrix = xgb.DMatrix(data=X_test,label=y_test,weight=X_test_wgt)\n",
    "\n",
    "    #perm = np.random.permutation(len(X_train))\n",
    "    #X_train = X_train[perm]\n",
    "    #y_train = y_train[perm]\n",
    "    #X_train_wgt = X_train_wgt[perm]\n",
    "\n",
    "    #perm = np.random.permutation(len(X_train))\n",
    "    #X_test = X_test[perm]\n",
    "    #y_test = y_test[perm]\n",
    "    #X_test_wgt = X_test_wgt[perm]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features(X, y, wgt, features, label):\n",
    "    fix, axs= plt.subplots(10,10, figsize=(40,40))\n",
    "    axs = axs.ravel()\n",
    "\n",
    "    for i,ax in enumerate(axs):\n",
    "        if i >= len(features):\n",
    "            continue\n",
    "        var=features[i]\n",
    "        if var=='weight':\n",
    "            continue\n",
    "        ax=axs[i]\n",
    "        #ax.hist(X_train[var], label='%s'%var)\n",
    "        ax.hist(X[var][y[:]==0 ], weights=wgt[y[:]==0 ], density=True, alpha=0.5, bins=20)\n",
    "        ax.hist(X[var][y[:]==1 ], weights=wgt[y[:]==1 ], density=True, alpha=0.5, bins=20)\n",
    "        #ax.set_yscale('log')\n",
    "        ax.set_title('%s dataset'%label)\n",
    "        ax.set_xlabel(var)\n",
    "    plt.show()\n",
    "    plt.hist(wgt[y[:]==0 ], alpha=0.5, bins=np.linspace(0,20,200))\n",
    "    plt.yscale(\"log\")\n",
    "    plt.hist(wgt[y[:]==1 ], alpha=0.5, bins=np.linspace(0,20,200))\n",
    "    plt.title('%s dataset')\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalized=True, cmap='bone'):\n",
    "    plt.figure(figsize=[7, 6])\n",
    "    norm_cm = cm\n",
    "    if normalized:\n",
    "        norm_cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        sns.heatmap(norm_cm, annot=cm, fmt='g', xticklabels=classes, yticklabels=classes, cmap=cmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "debug=False\n",
    "data_tth_orig = load_data(debug=debug)\n",
    "data_tth=data_tth_orig # save the original\n",
    "data_tth=dejag_data(data_tth, debug=debug)\n",
    "data_tth=remove_masses(data_tth, debug=debug)\n",
    "    \n",
    "the_initial_vars=load_feature_names(useJets=0, debug=debug) # add \"useJets\" quadrimomenta of jets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a single model (the basic template)\n",
    "\n",
    "def train_single_model(data, features, oddevensplit=True, fillna=False, debug=False):\n",
    "    # Start with a first thing with all variables\n",
    "    datasets= get_train_and_test(data, features, oddevensplit=oddevensplit, fillna=fillna, debug=debug)\n",
    "    X_train     = datasets['X_train']\n",
    "    X_test      = datasets['X_test']\n",
    "    X_train_wgt = datasets['X_train_wgt']\n",
    "    X_test_wgt  = datasets['X_test_wgt']\n",
    "    y_train     = datasets['y_train']\n",
    "    y_test      = datasets['y_test']\n",
    "\n",
    "    if debug:\n",
    "        plot_features(X_train, y_train, X_train_wgt, the_initial_vars, 'training')\n",
    "        plot_features(X_test , y_test , X_test_wgt , the_initial_vars, 'test')\n",
    "    # WORKING PROTOTYPE: xg_class = xgb.XGBClassifier(n_estimators=120, max_depth=3, learning_rate=0.1, subsample=0.8, colsample_bytree=0.8, gamma=1)\n",
    "    xg_class = xgb.XGBClassifier(n_estimators=120, max_depth=4, learning_rate=0.1, subsample=0.8, colsample_bytree=1, gamma=1)\n",
    "    eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "    xg_class.fit(X=X_train,y=y_train,eval_metric=[\"error\", \"logloss\"], early_stopping_rounds=10, eval_set=eval_set,sample_weight=X_train_wgt,sample_weight_eval_set=[X_train_wgt, X_test_wgt])\n",
    "\n",
    "    preds_train = xg_class.predict_proba(X_train)[:,0]\n",
    "    preds_test = xg_class.predict_proba(X_test)[:,0]\n",
    "\n",
    "    #preds_train=np.argmax(xg_class.predict_proba(X_train), axis=1)\n",
    "    #preds_test =np.argmax(xg_class.predict_proba(X_test), axis=1)\n",
    "\n",
    "    preds_cat_train = xg_class.predict(X_train)\n",
    "    preds_cat_test  = xg_class.predict(X_test)\n",
    "    # ROC curves\n",
    "    auc_train=plot_roc(y_train, preds_train, sample_weight=X_train_wgt, label='training', plot=False, debug=False)\n",
    "    auc_test=plot_roc(y_test, preds_test, sample_weight=X_test_wgt, label='test', plot=False, debug=False)\n",
    "\n",
    "    accuracy_train = accuracy_score(y_train, preds_cat_train,sample_weight=X_train_wgt)\n",
    "    print(\"Accuracy (train): %.2f%%\" % (accuracy_train * 100.0))\n",
    "    accuracy_test = accuracy_score(y_test, preds_cat_test, sample_weight=X_test_wgt)\n",
    "    print(\"Accuracy (test): %.2f%%\" % (accuracy_test * 100.0))\n",
    "\n",
    "    if debug:\n",
    "        xgb.plot_importance(xg_class)\n",
    "        plt.figure(figsize = (16, 12))\n",
    "        plt.show()        \n",
    "        results = xg_class.evals_result()\n",
    "        epochs = len(results['validation_0']['logloss'])\n",
    "        x_axis = range(0, epochs)\n",
    "        # plot log loss\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(x_axis, results['validation_0']['logloss'], label='Train')\n",
    "        ax.plot(x_axis, results['validation_1']['logloss'], label='Test')\n",
    "        ax.legend()\n",
    "        plt.ylabel('Log Loss')\n",
    "        plt.title('XGBoost Log Loss')\n",
    "        plt.show()\n",
    "        # plot classification error\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(x_axis, results['validation_0']['error'], label='Train')\n",
    "        ax.plot(x_axis, results['validation_1']['error'], label='Test')\n",
    "        ax.legend()\n",
    "        plt.ylabel('Classification Error')\n",
    "        plt.title('XGBoost Classification Error')\n",
    "        plt.show()\n",
    "\n",
    "        cm = confusion_matrix(y_test, preds_cat_test, sample_weight=X_test_wgt)\n",
    "        plot_confusion_matrix(cm, ['CP odd', 'CP even'])\n",
    "        plot_rel_pred(y_test, preds_test, 'test')\n",
    "        plot_pred(y_test, preds_test, 'test')\n",
    "        plot_weights(X_test_wgt, y_test, 'test')\n",
    "        \n",
    "    return {'auc_train': auc_train, 'auc_test': auc_test, 'model': xg_class, 'features': features, 'sorted_importance': dict(sorted(train_res['model'].get_booster().get_score(importance_type='weight').items(), key=lambda item: item[1])) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.17432\tvalidation_0-logloss:0.65071\tvalidation_1-error:0.17777\tvalidation_1-logloss:0.65137\n",
      "Multiple eval metrics have been passed: 'validation_1-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-logloss hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-error:0.17394\tvalidation_0-logloss:0.61644\tvalidation_1-error:0.17761\tvalidation_1-logloss:0.61760\n",
      "[2]\tvalidation_0-error:0.17432\tvalidation_0-logloss:0.58813\tvalidation_1-error:0.17732\tvalidation_1-logloss:0.58974\n",
      "[3]\tvalidation_0-error:0.17477\tvalidation_0-logloss:0.56451\tvalidation_1-error:0.17720\tvalidation_1-logloss:0.56673\n",
      "[4]\tvalidation_0-error:0.17443\tvalidation_0-logloss:0.54476\tvalidation_1-error:0.17718\tvalidation_1-logloss:0.54760\n",
      "[5]\tvalidation_0-error:0.17443\tvalidation_0-logloss:0.52830\tvalidation_1-error:0.17714\tvalidation_1-logloss:0.53169\n",
      "[6]\tvalidation_0-error:0.17443\tvalidation_0-logloss:0.51454\tvalidation_1-error:0.17714\tvalidation_1-logloss:0.51847\n",
      "[7]\tvalidation_0-error:0.17443\tvalidation_0-logloss:0.50283\tvalidation_1-error:0.17714\tvalidation_1-logloss:0.50735\n",
      "[8]\tvalidation_0-error:0.17409\tvalidation_0-logloss:0.49300\tvalidation_1-error:0.17714\tvalidation_1-logloss:0.49808\n",
      "[9]\tvalidation_0-error:0.17443\tvalidation_0-logloss:0.48452\tvalidation_1-error:0.17714\tvalidation_1-logloss:0.49011\n",
      "[10]\tvalidation_0-error:0.17443\tvalidation_0-logloss:0.47741\tvalidation_1-error:0.17714\tvalidation_1-logloss:0.48353\n",
      "[11]\tvalidation_0-error:0.17443\tvalidation_0-logloss:0.47137\tvalidation_1-error:0.17714\tvalidation_1-logloss:0.47799\n",
      "[12]\tvalidation_0-error:0.17409\tvalidation_0-logloss:0.46622\tvalidation_1-error:0.17713\tvalidation_1-logloss:0.47353\n",
      "[13]\tvalidation_0-error:0.17400\tvalidation_0-logloss:0.46185\tvalidation_1-error:0.17683\tvalidation_1-logloss:0.46974\n",
      "[14]\tvalidation_0-error:0.17400\tvalidation_0-logloss:0.45795\tvalidation_1-error:0.17693\tvalidation_1-logloss:0.46636\n",
      "[15]\tvalidation_0-error:0.17400\tvalidation_0-logloss:0.45473\tvalidation_1-error:0.17719\tvalidation_1-logloss:0.46357\n",
      "[16]\tvalidation_0-error:0.17434\tvalidation_0-logloss:0.45189\tvalidation_1-error:0.17715\tvalidation_1-logloss:0.46132\n",
      "[17]\tvalidation_0-error:0.17428\tvalidation_0-logloss:0.44942\tvalidation_1-error:0.17716\tvalidation_1-logloss:0.45941\n",
      "[18]\tvalidation_0-error:0.17428\tvalidation_0-logloss:0.44734\tvalidation_1-error:0.17716\tvalidation_1-logloss:0.45783\n",
      "[19]\tvalidation_0-error:0.17400\tvalidation_0-logloss:0.44541\tvalidation_1-error:0.17716\tvalidation_1-logloss:0.45655\n",
      "[20]\tvalidation_0-error:0.17392\tvalidation_0-logloss:0.44380\tvalidation_1-error:0.17719\tvalidation_1-logloss:0.45549\n",
      "[21]\tvalidation_0-error:0.17358\tvalidation_0-logloss:0.44241\tvalidation_1-error:0.17720\tvalidation_1-logloss:0.45451\n",
      "[22]\tvalidation_0-error:0.17346\tvalidation_0-logloss:0.44121\tvalidation_1-error:0.17720\tvalidation_1-logloss:0.45372\n",
      "[23]\tvalidation_0-error:0.17358\tvalidation_0-logloss:0.44013\tvalidation_1-error:0.17723\tvalidation_1-logloss:0.45307\n",
      "[24]\tvalidation_0-error:0.17324\tvalidation_0-logloss:0.43914\tvalidation_1-error:0.17723\tvalidation_1-logloss:0.45255\n",
      "[25]\tvalidation_0-error:0.17324\tvalidation_0-logloss:0.43828\tvalidation_1-error:0.17722\tvalidation_1-logloss:0.45212\n",
      "[26]\tvalidation_0-error:0.17317\tvalidation_0-logloss:0.43748\tvalidation_1-error:0.17725\tvalidation_1-logloss:0.45174\n",
      "[27]\tvalidation_0-error:0.17283\tvalidation_0-logloss:0.43673\tvalidation_1-error:0.17723\tvalidation_1-logloss:0.45149\n",
      "[28]\tvalidation_0-error:0.17283\tvalidation_0-logloss:0.43609\tvalidation_1-error:0.17722\tvalidation_1-logloss:0.45127\n",
      "[29]\tvalidation_0-error:0.17274\tvalidation_0-logloss:0.43542\tvalidation_1-error:0.17724\tvalidation_1-logloss:0.45110\n",
      "[30]\tvalidation_0-error:0.17283\tvalidation_0-logloss:0.43493\tvalidation_1-error:0.17724\tvalidation_1-logloss:0.45089\n",
      "[31]\tvalidation_0-error:0.17292\tvalidation_0-logloss:0.43434\tvalidation_1-error:0.17722\tvalidation_1-logloss:0.45065\n",
      "[32]\tvalidation_0-error:0.17280\tvalidation_0-logloss:0.43389\tvalidation_1-error:0.17720\tvalidation_1-logloss:0.45046\n",
      "[33]\tvalidation_0-error:0.17283\tvalidation_0-logloss:0.43337\tvalidation_1-error:0.17722\tvalidation_1-logloss:0.45037\n",
      "[34]\tvalidation_0-error:0.17269\tvalidation_0-logloss:0.43269\tvalidation_1-error:0.17722\tvalidation_1-logloss:0.45024\n",
      "[35]\tvalidation_0-error:0.17266\tvalidation_0-logloss:0.43215\tvalidation_1-error:0.17722\tvalidation_1-logloss:0.45010\n",
      "[36]\tvalidation_0-error:0.17266\tvalidation_0-logloss:0.43172\tvalidation_1-error:0.17724\tvalidation_1-logloss:0.45003\n",
      "[37]\tvalidation_0-error:0.17266\tvalidation_0-logloss:0.43123\tvalidation_1-error:0.17724\tvalidation_1-logloss:0.44991\n",
      "[38]\tvalidation_0-error:0.17233\tvalidation_0-logloss:0.43084\tvalidation_1-error:0.17722\tvalidation_1-logloss:0.44984\n",
      "[39]\tvalidation_0-error:0.17225\tvalidation_0-logloss:0.43037\tvalidation_1-error:0.17724\tvalidation_1-logloss:0.44983\n",
      "[40]\tvalidation_0-error:0.17228\tvalidation_0-logloss:0.42993\tvalidation_1-error:0.17726\tvalidation_1-logloss:0.44979\n",
      "[41]\tvalidation_0-error:0.17225\tvalidation_0-logloss:0.42952\tvalidation_1-error:0.17728\tvalidation_1-logloss:0.44979\n",
      "[42]\tvalidation_0-error:0.17213\tvalidation_0-logloss:0.42925\tvalidation_1-error:0.17729\tvalidation_1-logloss:0.44974\n",
      "[43]\tvalidation_0-error:0.17212\tvalidation_0-logloss:0.42889\tvalidation_1-error:0.17729\tvalidation_1-logloss:0.44971\n",
      "[44]\tvalidation_0-error:0.17211\tvalidation_0-logloss:0.42863\tvalidation_1-error:0.17729\tvalidation_1-logloss:0.44970\n",
      "[45]\tvalidation_0-error:0.17162\tvalidation_0-logloss:0.42842\tvalidation_1-error:0.17729\tvalidation_1-logloss:0.44959\n",
      "[46]\tvalidation_0-error:0.17162\tvalidation_0-logloss:0.42801\tvalidation_1-error:0.17695\tvalidation_1-logloss:0.44959\n",
      "[47]\tvalidation_0-error:0.17158\tvalidation_0-logloss:0.42745\tvalidation_1-error:0.17702\tvalidation_1-logloss:0.44962\n",
      "[48]\tvalidation_0-error:0.17116\tvalidation_0-logloss:0.42700\tvalidation_1-error:0.17698\tvalidation_1-logloss:0.44970\n",
      "[49]\tvalidation_0-error:0.17098\tvalidation_0-logloss:0.42658\tvalidation_1-error:0.17704\tvalidation_1-logloss:0.44966\n",
      "[50]\tvalidation_0-error:0.17047\tvalidation_0-logloss:0.42631\tvalidation_1-error:0.17709\tvalidation_1-logloss:0.44969\n",
      "[51]\tvalidation_0-error:0.17039\tvalidation_0-logloss:0.42617\tvalidation_1-error:0.17707\tvalidation_1-logloss:0.44969\n",
      "[52]\tvalidation_0-error:0.17036\tvalidation_0-logloss:0.42589\tvalidation_1-error:0.17707\tvalidation_1-logloss:0.44962\n",
      "[53]\tvalidation_0-error:0.17037\tvalidation_0-logloss:0.42569\tvalidation_1-error:0.17703\tvalidation_1-logloss:0.44964\n",
      "[54]\tvalidation_0-error:0.17003\tvalidation_0-logloss:0.42542\tvalidation_1-error:0.17703\tvalidation_1-logloss:0.44973\n",
      "[55]\tvalidation_0-error:0.17007\tvalidation_0-logloss:0.42516\tvalidation_1-error:0.17713\tvalidation_1-logloss:0.44982\n",
      "[56]\tvalidation_0-error:0.16982\tvalidation_0-logloss:0.42491\tvalidation_1-error:0.17707\tvalidation_1-logloss:0.44985\n",
      "Stopping. Best iteration:\n",
      "[46]\tvalidation_0-error:0.17162\tvalidation_0-logloss:0.42801\tvalidation_1-error:0.17695\tvalidation_1-logloss:0.44959\n",
      "\n",
      "Accuracy (train): 82.84%\n",
      "Accuracy (test): 82.30%\n",
      "AUC train: 0.6912883062694979\n",
      "AUC test: 0.6912883062694979\n",
      "Variable importance {'dEtaBB_2lss': 59, 'mTTH_2lss1tau': 79, 'Lep2_eta': 28, 'mindr_lep1_jet': 75, 'met': 32, 'dPhiLL_BBframe_2lss': 41, 'Lep1_eta': 34, 'dEtaLL_BBframe_2lss': 37, 'mindr_lep2_jet': 43, 'Tau_phi': 14, 'met_phi': 19, 'dEtaBB_LLframe_2lss': 29, 'Lep2_phi': 34, 'thetaTopTop_ttbarframe_2lss1tau': 40, 'Tau_pt': 36, 'Lep2_pt': 28, 'dPhiBB_LLframe_2lss': 24, 'Tau_eta': 27, 'Lep1_pt': 13, 'theta_higgs_ttbar_TTHsystem_2lss1tau': 10, 'Lep1_phi': 27, 'HTT_score': 22, 'Hj_tagger_hadTop': 22, 'nSelJets': 9, 'avg_dr_jet': 25}\n"
     ]
    }
   ],
   "source": [
    "# Run on a single model\n",
    "if True:\n",
    "    train_res= train_single_model(data_tth, the_initial_vars, oddevensplit=True, fillna=False, debug=False)\n",
    "    print('AUC train:', train_res['auc_train'])\n",
    "    print('AUC test:', train_res['auc_train'])\n",
    "    print('Sorted variable importance', train_res['sorted_importance'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nSelJets': 9, 'theta_higgs_ttbar_TTHsystem_2lss1tau': 10, 'Lep1_pt': 13, 'Tau_phi': 14, 'met_phi': 19, 'HTT_score': 22, 'Hj_tagger_hadTop': 22, 'dPhiBB_LLframe_2lss': 24, 'avg_dr_jet': 25, 'Tau_eta': 27, 'Lep1_phi': 27, 'Lep2_eta': 28, 'Lep2_pt': 28, 'dEtaBB_LLframe_2lss': 29, 'met': 32, 'Lep1_eta': 34, 'Lep2_phi': 34, 'Tau_pt': 36, 'dEtaLL_BBframe_2lss': 37, 'thetaTopTop_ttbarframe_2lss1tau': 40, 'dPhiLL_BBframe_2lss': 41, 'mindr_lep2_jet': 43, 'dEtaBB_2lss': 59, 'mindr_lep1_jet': 75, 'mTTH_2lss1tau': 79}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "\n",
    "convert_model(model,input_variables=input_vars,output_xml=os.path.join(save_dir,'xgboost-{}.xml'.format(channel)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
